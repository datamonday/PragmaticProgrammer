[toc]

# 1. 算法性能分析

## 1.1 时间复杂度

### 1）什么是时间复杂度

**时间复杂度是一个函数，它定性描述该算法的运行时间**。

在软件开发中，时间复杂度就是用来方便开发者估算出程序运行的大体时间。通常会估算算法的操作单元数量来代表程序消耗的时间，这里默认CPU的每个单元运行消耗的时间都是相同的。

假设算法的问题规模为n，那么操作单元数量便用函数 `f(n)` 来表示，随着数据规模 `n` 的增大，算法执行时间的增长率和 `f(n)` 的增长率相同，这称作为算法的渐近时间复杂度，简称时间复杂度，记为 `O(f(n))`。

### 2）什么是大O

算法导论给出的解释：**大O用来表示上界的**，当用它作为算法的最坏情况运行时间的上界，就是对任意数据输入的运行时间的上界。

同样算法导论给出了例子：拿插入排序来说，插入排序的时间复杂度我们都说是O(n^2) 。

输入数据的形式对程序运算时间是有很大影响的，在数据本来有序的情况下时间复杂度是O(n)，但如果数据是逆序的话，插入排序的时间复杂度就是O(n^2)，也就对于所有输入情况来说，最坏是O(n^2) 的时间复杂度，所以称插入排序的时间复杂度为O(n^2)。

同样的同理再看一下快速排序，都知道快速排序是O(nlogn)，但是当数据已经有序情况下，快速排序的时间复杂度是O(n^2) 的，**所以严格从大O的定义来讲，快速排序的时间复杂度应该是O(n^2)**。

**但是我们依然说快速排序是O(nlogn)的时间复杂度，这个就是业内的一个默认规定，这里说的O代表的就是一般情况，而不是严格的上界**。如图所示：
![时间复杂度4，一般情况下的时间复杂度](https://img-blog.csdnimg.cn/20200728185745611.png)

我们主要关心的还是一般情况下的数据形式。

**面试中说道算法的时间复杂度是多少指的都是一般情况**。但是深入探讨一个算法的实现以及性能的时候，就要时刻想着数据用例的不一样，时间复杂度也是不同的。


### 3）不同数据规模的差异

下图可以看出不同算法的时间复杂度在不同数据输入规模下的差异。

![时间复杂度，不同数据规模的差异](https://img-blog.csdnimg.cn/20200728191447384.png)

在决定使用哪些算法的时候，不是时间复杂越低的越好（因为简化后的时间复杂度忽略了常数项等等），要考虑数据规模，如果数据规模很小，用O(n^2)的算法比O(n)的更合适（在有常数项的时候）。

就像上图中 O(5n^2) 和 O(100n) 在n为20之前 很明显 O(5n^2)是更优的，所花费的时间也是最少的。

为什么在计算时间复杂度时要忽略常数项系数？即O(100n) 的时间复杂度是O(n)，O(5n^2)的时间复杂度是O(n^2)，而且要默认O(n) 优于O(n^2) 呢 ？

这里就又涉及到大O的定义，**因为大O就是数据量级突破一个点且数据量级非常大的情况下所表现出的时间复杂度，这个数据量也就是常数项系数已经不起决定性作用的数据量**。

例如上图中20就是那个点，只要 n>20 常数项系数已经不起决定性作用了。

**所以我们说的时间复杂度都是省略常数项系数的，是因为一般情况下都是默认数据规模足够的大，基于这样的事实，给出的算法时间复杂的的一个排行如下所示**：

```bash
O(1)常数阶 < O(logn)对数阶 < O(n)线性阶 < O(n^2)平方阶 < O(n^3)立方阶 < O(2^n)指数阶
```

但是也要注意大常数，如果这个常数非常大，例如10^7 ，10^9 ，那么常数就是不得不考虑的因素了。

### 4）复杂表达式的化简

有时候计算时间复杂度不是一个简单的O(n) 或者O(n^2)， 而是一个复杂的表达式，例如：

```
O(2*n^2 + 10*n + 1000)
```

那如何描述这个算法的时间复杂度呢，一种方法就是简化法。

1. 去掉运行时间中的加法常数项 （因为常数项并不会因为n的增大而增加计算机的操作次数）。

```
O(2*n^2 + 10*n)
```

2. 去掉常数系数（上文中已经详细讲过为什么可以去掉常数项的原因）。

```
O(n^2 + n)
```

3. 只保留保留最高项，去掉数量级小一级的n （因为n^2 的数据规模远大于n），最终简化为：

```
O(n^2)
```

如果这一步理解有困难，那也可以做提取n的操作，变成O(n(n+1)) ，省略加法常数项后也就别变成了：

```
O(n^2)
```

所以最后说这个算法的算法时间复杂度是O(n^2) 。

### 5）`O(logn)`中的log是以什么为底？

算法的时间复杂度是logn的，那么一定是以2为底n的对数么？

其实不然，也可以是以10为底n的对数，也可以是以20为底n的对数，**但我们统一说 logn，也就是忽略底数的描述**。为什么可以这么做呢？如下图所示：

![时间复杂度1.png](https://img-blog.csdnimg.cn/20200728191447349.png)


假如有两个算法的时间复杂度，分别是log以2为底n的对数和log以10为底n的对数，那么 `以2为底n的对数 = 以2为底10的对数 * 以10为底n的对数`。

而以2为底10的对数是一个常数，计算时间复杂度是忽略常数项系数的。抽象一下就是在时间复杂度的计算过程中，`log以i为底n的对数 = log以j为底n的对数`，所以忽略了i，直接说是logn。这样就应该不难理解为什么忽略底数了。

### 6）算法实例分析

通过这道面试题目，来分析一下时间复杂度。题目描述：

> 找出 n 个字符串中相同的两个字符串（假设这里只有两个相同的字符串）。

如果是暴力枚举的话，时间复杂度是多少呢，是O(n^2)么？

**题目分析**：字符串比较不像 int 型数字比较那么简单，除了 n^2 次的遍历次数外，字符串比较要消耗 m 次操作（m 也就是字母串的长度），所以时间复杂度是 `O(m×n×n)`。

**解题思路**：先排对 n 个字符串按字典序排序，排序后 n 个字符串就是有序的，意味着两个相同的字符串就是挨在一起，然后再遍历 n 个字符串，这样就找到两个相同的字符串了。

**时间复杂度分析**：快速排序时间复杂度为 `O(nlogn)`，快速排序每次的比较都要有 m 次的字符比较的操作，就是 `O(m×n×logn)`。之后还要遍历一遍这 n 个字符串找出两个相同的字符串，遍历时依然要比较字符串，所以时间复杂度是 `O(m×n×logn + n×m)`。

**时间复杂度简化**：对 O(m×n×logn + n×m) 进行简化操作，把 m×n 提取出来变成 O(m×n×(logn+1))，再省略常数项最后的时间复杂度是 `O(m×n×logn)`。

显然，`O(m × n × logn)` 优于 `O(m × n × n)`。

**所以先把字符串集合排序再遍历一遍找到两个相同字符串的方法要比直接暴力枚举的方式更快**。这就是我们通过分析两种算法的时间复杂度得来的。**这不是最优解，仅仅是用这道题目来讲解一下时间复杂度**。


-----------------------
## 1.2 算法为什么会超时？

### 1）超时是怎么回事

![程序超时](https://img-blog.csdnimg.cn/20200729112716117.png)

leetcode上一种错误是“超时”。也就是说程序运行的时间超过了规定的时间，一般OJ（online judge）的超时时间就是1s，也就是用例数据输入后最多要1s内得到结果。

如果写出了一个 $O(n)$ 的算法 ，其实可以估算出来 $n$ 是多大的时候算法的执行时间就会超过1s了。如果 $n$ 的规模已经足够让$O(n)$的算法运行时间超过了1s，就应该考虑 $log(n)$ 的解法了。

### 2）从硬件配置看计算机的性能

计算机的运算速度主要看CPU的配置，以2015年MacPro为例，CPU配置：2.7 GHz Dual-Core Intel Core i5 。

1Hz = 1/s，1Hz 是CPU的一次脉冲（可以理解为一次改变状态，也叫时钟周期），称之为为赫兹。1GHz（兆赫）= 1000MHz（兆赫）；1MHz（兆赫）= 1百万赫兹。1GHz = 10亿Hz，表示CPU可以一秒脉冲10亿次（有10亿个时钟周期），这里不要简单理解一个时钟周期就是一次CPU运算。

例如 1+2=3，CPU要执行四次才能完成这个操作

- 把1放入寄存机
- 把2放入寄存器
- 做加法
- 保存3


CPU也要执行计算机的各种进程任务，我们的程序仅仅是其中的一个进程而已。所以计算机1s真正能执行多少次操作呢？

在写测试程序测1s内处理多大数量级数据的时候，有三点需要注意：

* CPU执行每条指令所需的时间并不相同，例如CPU执行加法和乘法操作的耗时不同。
* 现在大多计算机系统的内存管理都有缓存技术，所以频繁访问相同地址的数据和访问不相邻元素所需的时间也是不同的。
* 计算机同时运行多个程序，每个程序里还有不同的进程线程在抢占资源。

尽管有很多因素影响，但是还是可以对自己程序的运行时间有一个大体的评估的。引用算法4里面的一段话：

* 火箭科学家需要大致知道一枚试射火箭的着陆点是在大海里还是在城市中；
* 医学研究者需要知道一次药物测试是会杀死还是会治愈实验对象；

所以**任何开发计算机程序员的软件工程师都应该能够估计这个程序的运行时间是一秒钟还是一年**。以下以C++代码为例：

测试硬件：2015年MacPro。实现三个函数，时间复杂度分别是 $O(n)$ , $O(n^2)$, $O(n\log n)$，使用加法运算来统一测试。

```Java
import java.util.Scanner;

public class TimeComplexity {
    // o(n)
    public static void function1(long n) {
        System.out.println("o(n)算法");
        long k = 0;
        for (long i = 0; i < n; i++) {
            k++;
        }
    }

    // o(n^2)
    public static void function2(long n) {
        System.out.println("o(n^2)算法");
        long k = 0;
        for (long i = 0; i < n; i++) {
            for (long j = 0; j < n; j++) {
                k++;
            }
        }
    }

    // o(nlogn)
    public static void function3(long n) {
        System.out.println("o(nlogn)算法");
        long k = 0;
        for (long i = 0; i < n; i++) {
            for (long j = 1; j < n; j = j * 2) { // 注意这里j=1
                k++;
            }
        }
    }

    public static void main(String[] args) {
        while(true) {
            Scanner in = new Scanner(System.in);
            System.out.print("输入n: ");
            int n = in.nextInt();
            long startTime = System.currentTimeMillis();

            function1(n);
            // function2(n);
            // function3(n);

            long endTime = System.currentTimeMillis();
            long costTime = endTime - startTime;
            System.out.println("算法耗时 == " + costTime + "ms");
        }
    }
}
```

**整体测试数据整理如下：**

![程序超时1](https://img-blog.csdnimg.cn/20201208231559175.png)


-----------------------
## 1.3 空间复杂度分析

空间复杂度(Space Complexity)是对一个算法在运行过程中占用内存空间大小的量度，记做 `S(n)=O(f(n)`，依然使用大O来表示。利用程序的空间复杂度，可以对程序运行中需要多少内存有个预先估计。

关注空间复杂度有两个常见的相关问题：

1. 空间复杂度是考虑程序（可执行文件）的大小么？

程序运行时内存大小和程序本身的大小不要混淆。**空间复杂度是考虑程序运行时占用内存的大小，而不是可执行文件的大小**。

2. 空间复杂度是准确算出程序运行时所占用的内存么？

不是。很多因素会影响程序真正内存使用大小，例如编译器的内存对齐，编程语言容器的底层实现等等这些都会影响到程序内存的开销。所以空间复杂度是大体评估程序内存使用的大小。为了避免内存超出限制，需要对算法占用多大的内存有一个大体的预估。

来看一下例子，什么时候的空间复杂度是$O(1)$呢，C++代码如下：

```CPP
int j = 0;
for (int i = 0; i < n; i++) {
    j++;
}
```

随着n的变化，所需开辟的内存空间并不会随着 n 的变化而变化，即此算法空间复杂度为一个常量，表示为大O(1)。

当消耗空间和输入参数 n 保持线性增长，这样的空间复杂度为 O(n)

```CPP
int* a = new int(n);
for (int i = 0; i < n; i++) {
    a[i] = i;
}
```

上述代码中定义了一个数组，占用的大小为 n，随着n的增大，开辟的内存大小呈线性增长，即 O(n)。

## 1.4 递归算法的时间与空间复杂度分析

通过求斐波那契数列和二分法深入分析递归算法的时间和空间复杂度。


### 1）递归求斐波那契数列

求斐波那契数的递归写法

```python
def fib(n):
    if n <= 0:
        return 0
    elif n == 1 or n == 2:
        return 1
    else:
    	return fib(n-1) + fib(n-2)
```

递归算法，所用的存储空间少，但运行时需要的内存可不见得会少。

**时间复杂度分析**

递归算法的时间复杂度本质上是要看: **递归的次数 * 每次递归的时间复杂度**。

可以看出，上面的代码每次递归都是O(1)的操作。再来看递归了多少次，这里将i=5作为输入，递归过程抽象成一棵递归树，如图：

![递归空间复杂度分析](https://img-blog.csdnimg.cn/20210305093200104.png)

从图中可以看出，二叉树中每一个节点都是一次递归，一棵深度为 k 的二叉树最多可以有 `2^k - 1` 个节点。所以该递归算法的时间复杂度为 `O(2^n)`，这个复杂度是非常大的，随着 n 的增大，耗时是指数上升的。所以这种求斐波那契数的算法看似简洁，其实时间复杂度非常高，一般不推荐这样来实现斐波那契。

其实罪魁祸首就是这里的两次递归，导致了时间复杂度以指数上升。

```CPP
return fibonacci(i-1) + fibonacci(i-2);
```

可不可以优化一下这个递归算法呢。 主要是减少递归的调用次数。

来看一下如下代码：

```python
# 改进
def fib(first, second, n):
    if n <= 0:
        return 0
    
    if n <= 2:
        return 1
    
    elif n == 3:
        return first + second
    
    else:
        return fib(second, first+second, n - 1)
```

这里相当于**用first和second来记录当前相加的两个数值，此时就不用两次递归了**。

因为每次递归的时候 n-1，即只是递归了 n 次，所以时间复杂度是 `O(n)`。

递归的深度依然是 n，每次递归所需的空间也是常数，所以空间复杂度依然是 `O(n)`。

**空间复杂度分析**

**递归算法的空间复杂度 = 每次递归的空间复杂度 * 递归深度**

为什么要求递归的深度？

因为每次递归所需的空间都被压到调用栈里（这是内存管理里面的数据结构，和算法里的栈原理是一样的），一次递归结束，这个栈就是就是把本次递归的数据弹出去。所以这个栈最大的长度就是递归的深度。

此时可以分析这段递归的空间复杂度，从代码中可以看出每次递归所需要的空间大小都是一样的，所以每次递归中需要的空间是一个常量，并不会随着 n 的变化而变化，每次递归的空间复杂度就是$O(1)$。

递归的深度是多少呢？如图所示：

![递归空间复杂度分析](https://img-blog.csdnimg.cn/20210305094749554.png)

递归第 n 个斐波那契数的话，递归调用栈的深度就是n。

那么每次递归的空间复杂度是O(1)， 调用栈深度为n，所以这段递归代码的空间复杂度就是O(n)。


最后对各种求斐波那契数列方法的性能做一下分析，如题：

![递归的空间复杂度分析](https://img-blog.csdnimg.cn/20210305095227356.png)

可以看出，求斐波那契数的时候，使用递归算法并不一定是在性能上是最优的，但递归确实简化代码层面的复杂度。

### 2）递归实现二分法

注意：二分查找的前提数组或者列表有序。

```python
# 递归实现
def binary_search(od_list, key, left, right):
    if left > right:
        return None
    
    mid = (left + right) // 2
    if key == od_list[mid]:
        return mid
    elif key > od_list[mid]:
        return binary_search(od_list, key, mid+1, right)
    else:
        return binary_search(od_list, key, left, mid-1)
    
# 非递归实现
def binary_search(od_list, key, left, right):
    while left < right:
        mid = (left + right) // 2
        if key == od_list[mid]:
            return mid
        elif key > od_list[mid]:
            left = mid + 1
        else:
            right = mid - 1
    return None
```

都知道二分查找的时间复杂度是O(logn)，那么递归二分查找的空间复杂度是多少呢？

我们依然看 **每次递归的空间复杂度和递归的深度**

- 每次递归的空间复杂度：主要是参数里传入的这个arr数组，在C/C++中函数传递数组参数是传入的数组首元素地址。**也就是说每一层递归都是公用一块数组地址空间的**，所以每次递归的空间复杂度是常数即：O(1)。

- 递归的深度：二分查找的递归深度是 logn ，递归深度就是调用栈的长度，那么这段代码的空间复杂度为 1*logn = O(logn)。

注意，所用的语言在传递函数参数的时，是拷贝整个数值还是拷贝地址，**如果是拷贝整个数值那么该二分法的空间复杂度就是 O(nlogn)**。

> 注解：
>
> 传值就是传入一个参数的值，传址就是传入一个参数的地址，也就是内存的地址，相当于指针。区别是**如果函数里对传入的参数重新赋值，函数外的全局变量是否相应改变**。传值传入的参数不会改变，传址传入会改变。
>
> Python是不允许程序员选择采用传值还是传址的。Python参数传递采用的肯定是“传对象引用”的方式。实际上，这种方式相当于传值和传址的一种综合。如果函数收到的是一个可变对象（比如字典或者列表）的引用，就能修改对象的原始值——相当于传址。如果函数收到的是一个不可变对象（比如数字、字符或者元组）的引用，就不能直接修改原始对象——相当于传值。
> ————————————————
> 参考：https://blog.csdn.net/weixin_35511255/article/details/111958205



# 参考资料

> 《代码随想录》：https://github.com/youngyangyang04/leetcode-master